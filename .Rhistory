breaks = "sd",
palette="Oranges",
legend = "Number of melodies",
title="Number of melodies per region")
choropleth(ja, sub.jadat, adm.join = "NAME_1",
value = "Freq.y",
breaks = "sd",
palette="Oranges",
legend = "Number of melodies",
title="Number of melodies per region")
sub.jadat <- merge(jadat, sub.map, by="NAME_1", all.x=TRUE)
sub.jadat$Freq.y[is.na(sub.jadat$Freq.y)] <- 0
choropleth(ja, sub.jadat, adm.join = "NAME_1",
value = "Freq.y",
breaks = "sd",
palette="Oranges",
legend = "Number of melodies",
title="Number of melodies per region")
#US + Canada
sub.uscadat <- merge(uscadat, sub.map, by="NAME_1", all.x=TRUE)
sub.uscadat$Freq.y[is.na(sub.uscadat$Freq.y)] <- 0
choropleth(usacan, sub.uscadat, adm.join = "NAME_1",
value = "Freq.y",
breaks = "sd",
palette="Oranges",
legend = "Number of melodies",
title="Number of melodies per region")
sub.map
#UK
sub.ukdat <- merge(ukdat, sub.map, by="NAME_1", all.x=TRUE)
sub.ukdat$Freq.y[is.na(sub.ukdat$Freq.y)] <- 0
choropleth(uk, sub.ukdat, adm.join = "NAME_1",
value = "Freq",
breaks = "sd",
palette="Oranges",
legend = "Number of melodies",
title="Number of melodies per region")
choropleth(uk, sub.ukdat, adm.join = "NAME_1",
value = "Freq.y",
breaks = "sd",
palette="Oranges",
legend = "Number of melodies",
title="Number of melodies per region")
##### Figure of Japan (Single country) #####
BASEFILE <- "./GADM"
BASEURL <- "https://biogeo.ucdavis.edu/data/gadm3.6/Rsp/"
ja <- gadm_sp.loadCountries("JPN", level = 1, basefile=BASEFILE, baseurl=BASEURL, simplify=0.02)
jards<-full.jards<-readRDS(url("https://biogeo.ucdavis.edu/data/gadm3.6/Rsp/gadm36_JPN_1_sp.rds"))
jards@data <- merge(jards@data, map, by="NAME_1", all.x=TRUE)
jards@data$Freq[is.na(jards@data$Freq)] <- 0
jadat <- data.frame(NAME_1=jards@data$NAME_1, Freq=jards@data$Freq)
choropleth(ja, jadat, adm.join = "NAME_1",
value = "Freq",
breaks = "sd",
palette="Oranges",
legend = "Number of melodies",
title="Number of melodies per region")
##### Figure of US & Canada (Multiple countries) #####
BASEFILE <- "./GADM"
BASEURL <- "https://biogeo.ucdavis.edu/data/gadm3.6/Rsp/"
usacan <- gadm_sp.loadCountries(c("USA", "CAN"), level = 1, basefile=BASEFILE, baseurl=BASEURL, simplify=0.02)
usrds <- readRDS(url("https://biogeo.ucdavis.edu/data/gadm3.6/Rsp/gadm36_USA_1_sp.rds"))
usrds@data <- merge(usrds@data, map, by="NAME_1", all.x=TRUE)
usrds@data$Freq[is.na(usrds@data$Freq)] <- 0
usdat <- data.frame(NAME_1=usrds@data$NAME_1, Freq=usrds@data$Freq)
cards <- readRDS(url("https://biogeo.ucdavis.edu/data/gadm3.6/Rsp/gadm36_CAN_1_sp.rds"))
cards@data <- merge(cards@data, map, by="NAME_1", all.x=TRUE)
cards@data$Freq[is.na(cards@data$Freq)] <- 0
cadat <- data.frame(NAME_1=cards@data$NAME_1, Freq=cards@data$Freq)
uscadat <- rbind(usdat, cadat)
choropleth(usacan, uscadat, adm.join = "NAME_1",
value = "Freq",
breaks = "sd",
palette="Oranges",
legend = "Number of melodies",
title="Number of melodies per region")
##### Figure of UK (Single country) #####
BASEFILE <- "./GADM"
BASEURL <- "https://biogeo.ucdavis.edu/data/gadm3.6/Rsp/"
uk <- gadm_sp.loadCountries("GBR", level = 1, basefile=BASEFILE, baseurl=BASEURL, simplify=0.02)
ukrds<-readRDS(url("https://biogeo.ucdavis.edu/data/gadm3.6/Rsp/gadm36_GBR_1_sp.rds"))
ukrds@data <- merge(ukrds@data, map, by="NAME_1", all.x=TRUE)
ukrds@data$Freq[is.na(ukrds@data$Freq)] <- 0
ukdat <- data.frame(NAME_1=ukrds@data$NAME_1, Freq=ukrds@data$Freq)
choropleth(uk, ukdat, adm.join = "NAME_1",
value = "Freq",
breaks = "sd",
palette="Oranges",
legend = "Number of melodies",
title="Number of melodies per region")
<-read.csv("https://raw.githubusercontent.com/pesavage/melodic-evolution/master/MelodicEvoSeq.csv",header=TRUE,row.names=1) #Import all 10,000+ sequences
s <- d <- subset(full, PairNo>0)  #Restrict to only highly related pairs
map <- as.data.frame(table(full$NAME_1))
map <- rename(map, NAME_1 = Var1)
attach(map)
map <- map[order(-Freq),]
detach(map)
barplot(map$Freq,las=2,names.arg=map$Var1, cex.names=.7)
write.csv(map,"MapSampleNos.csv")
map <- read.csv("MapSampleNos.csv",row.names=1)
sub.map <- as.data.frame(table(d$NAME_1))
sub.map <- rename(sub.map, NAME_1 = Var1)
attach(sub.map)
sub.map <- sub.map[order(-Freq),]
detach(sub.map)
barplot(sub.map$Freq,las=2,names.arg=map$Var1, cex.names=.7)
write.csv(sub.map,"SubMapSampleNos.csv")
sub.map <- read.csv("SubMapSampleNos.csv",row.names=1)
##### Figure of Japan (Single country) #####
BASEFILE <- "./GADM"
BASEURL <- "https://biogeo.ucdavis.edu/data/gadm3.6/Rsp/"
ja <- gadm_sp.loadCountries("JPN", level = 1, basefile=BASEFILE, baseurl=BASEURL, simplify=0.02)
jards<-full.jards<-readRDS(url("https://biogeo.ucdavis.edu/data/gadm3.6/Rsp/gadm36_JPN_1_sp.rds"))
jards@data <- merge(jards@data, map, by="NAME_1", all.x=TRUE)
jards@data$Freq[is.na(jards@data$Freq)] <- 0
jadat <- data.frame(NAME_1=jards@data$NAME_1, Freq=jards@data$Freq)
choropleth(ja, jadat, adm.join = "NAME_1",
value = "Freq",
breaks = "sd",
palette="Oranges",
legend = "Number of melodies",
title="Number of melodies per region")
##### Figure of US & Canada (Multiple countries) #####
BASEFILE <- "./GADM"
BASEURL <- "https://biogeo.ucdavis.edu/data/gadm3.6/Rsp/"
usacan <- gadm_sp.loadCountries(c("USA", "CAN"), level = 1, basefile=BASEFILE, baseurl=BASEURL, simplify=0.02)
usrds <- readRDS(url("https://biogeo.ucdavis.edu/data/gadm3.6/Rsp/gadm36_USA_1_sp.rds"))
usrds@data <- merge(usrds@data, map, by="NAME_1", all.x=TRUE)
usrds@data$Freq[is.na(usrds@data$Freq)] <- 0
usdat <- data.frame(NAME_1=usrds@data$NAME_1, Freq=usrds@data$Freq)
cards <- readRDS(url("https://biogeo.ucdavis.edu/data/gadm3.6/Rsp/gadm36_CAN_1_sp.rds"))
cards@data <- merge(cards@data, map, by="NAME_1", all.x=TRUE)
cards@data$Freq[is.na(cards@data$Freq)] <- 0
cadat <- data.frame(NAME_1=cards@data$NAME_1, Freq=cards@data$Freq)
uscadat <- rbind(usdat, cadat)
choropleth(usacan, uscadat, adm.join = "NAME_1",
value = "Freq",
breaks = "sd",
palette="Oranges",
legend = "Number of melodies",
title="Number of melodies per region")
##### Figure of UK (Single country) #####
BASEFILE <- "./GADM"
BASEURL <- "https://biogeo.ucdavis.edu/data/gadm3.6/Rsp/"
uk <- gadm_sp.loadCountries("GBR", level = 1, basefile=BASEFILE, baseurl=BASEURL, simplify=0.02)
ukrds<-readRDS(url("https://biogeo.ucdavis.edu/data/gadm3.6/Rsp/gadm36_GBR_1_sp.rds"))
ukrds@data <- merge(ukrds@data, map, by="NAME_1", all.x=TRUE)
ukrds@data$Freq[is.na(ukrds@data$Freq)] <- 0
ukdat <- data.frame(NAME_1=ukrds@data$NAME_1, Freq=ukrds@data$Freq)
choropleth(uk, ukdat, adm.join = "NAME_1",
value = "Freq",
breaks = "sd",
palette="Oranges",
legend = "Number of melodies",
title="Number of melodies per region")
map
system("defaults write org.R-project.R force.LANG en_US.UTF-8")
?std.error
??std.error
??std.error
install.packages("plotrix")
library(plotrix)
?ggplot
??ggplot
library(ggplot2)
?ggplot
install.packages("googlesheets4")
library(irr)
library(psych)
library(googlesheets4)
library(lsr)
library(pwr)
options(stringsAsFactors = FALSE)
#Read full Cantometrics data from Google Sheets:
(c <- as.data.frame(read_sheet("https://docs.google.com/spreadsheets/d/1AjynK9mMQTw58B_B8b_ZIip3fyUm-aoV7Pp21HziBb0/edit?ts=5edaae90#gid=974103515")))
devtools::install_github("tidyverse/googlesheets4")
install.packages("googlesheets4")
install.packages("googlesheets4")
install.packages("googlesheets4")
install.packages("googlesheets4")
install.packages("googlesheets4")
library(irr)
library(psych)
library(googlesheets4)
library(lsr)
library(pwr)
options(stringsAsFactors = FALSE)
#Read full Cantometrics data from Google Sheets:
(c <- as.data.frame(read_sheet("https://docs.google.com/spreadsheets/d/1AjynK9mMQTw58B_B8b_ZIip3fyUm-aoV7Pp21HziBb0/edit?ts=5edaae90#gid=974103515")))
devtools::install_github("tidyverse/googlesheets4",force=TRUE)
load("/Users/pesavage/Downloads/MSP_Supplementary/MSP_TableData.Rdata")
View(AggrDat)
load("/Users/pesavage/Downloads/MSP_Supplementary/PolsVars.Rdata")
View(variables)
View(polities_all)
View(polities)
View(NGAs)
View(CanonVars)
View(ArchaeoVars)
View(AggrDat)
source("install.R")
#If Biostrings is already installed you can comment out the following three lines of code:
if (!requireNamespace("BiocManager", quietly = TRUE)){
install.packages("BiocManager")
BiocManager::install("Biostrings") #If not yet installed, follow installation instructions
}
#open packages
library(plotrix)
library(seqinr)
library(Biostrings)
library(seriation)
library(tidyr)
library(ggplot2)
library(dplyr)
library(varhandle)
library(stringr)
library(seqRFLP)
library(pwr)
library(lsr)
library(sp)
library(RColorBrewer)
library(phangorn)
library(GADMTools)
# Make directories to store results if they don't exist
if(!dir.exists("results/")) dir.create("results/")
if(!dir.exists("figures/")) dir.create("figures/")
# To calculate distance matrices
#source(PID.R) #uncomment this to recalculate distance matrices of PID among the 10,064 melodic variants, but be aware that this will take up to a month on a standard computer!
#source(Dist.R) # uncomment this to re-dentify highly related pairs of melodies
##### Calculate evolutionary rates of highly-related melodic variant pairs ####
# Import all 10,000+ sequences.
# The highly related pairs were automatically identified using the scripts in "PID.R" and "Dist.R", but a lot of manual work was required to align related pairs, code functional positions, and count the numbers and sizes of all mutation types to create the "MelodicEvoSeq.csv" file used for subsequent analyses
full<-read.csv("MelodicEvoSeq.csv", header=TRUE, row.names=1)
d <- subset(full, PairNo>0)  #Restrict to only highly related pairs
## Source analysis function
source("MelodicEvoAnalysis_SP.R")
##### Calculate mutation rates for different functional types ####
# Full English subset
english <- subset(d, Language=="English")
MelodicEvoAnalysis(english, "english")
library(TOSTER)
r <- 0.23
d <- 2*r / (sqrt(1-r^2))
r_u <- 0.3
r_l <- -0.3
d_u <- 2*r_u / (sqrt(1-r_u^2))
d_l <- 2*r_l / (sqrt(1-r_l^2))
install.packages("TOSTER")
library(TOSTER)
r <- 0.23
d <- 2*r / (sqrt(1-r^2))
r_u <- 0.3
r_l <- -0.3
d_u <- 2*r_u / (sqrt(1-r_u^2))
d_l <- 2*r_l / (sqrt(1-r_l^2))
TOSTmeta(ES = d, se=0.003, low_eqbound_d=d_l, high_eqbound_d=d_u, alpha=0.05)
?TOSTmeta
?TOSTER
??TOSTER
TOSTr(n=48, r = 0.23, low_eqbound_r=-0.3, high_eqbound_r=0.3, alpha=0.05)
TOSTr(n=60, r = 0.23, low_eqbound_r=-0.3, high_eqbound_r=0.3, alpha=0.05)
TOSTr(n=30, r = 0.23, low_eqbound_r=-0.3, high_eqbound_r=0.3, alpha=0.05)
TOSTr(n=60, r = 0.6, low_eqbound_r=-0.3, high_eqbound_r=0.3, alpha=0.05)
TOSTr(n=60, r = 0.05, low_eqbound_r=-0.3, high_eqbound_r=0.3, alpha=0.05)
library(vegan)
library(pwr)
pwr.t.test(d=.4,sig.level=.05, type="paired",alternative="greater")
pwr.t.test(n=NULL, d=.4,sig.level=.05, type="paired",alternative="greater")
pwr.t.test(d=.4,sig.level=.05, power=.8, type="paired",alternative="greater")
pwr.t.test(d=.4,sig.level=(.05/6), power=.8, type="paired",alternative="greater")
pwr.t.test(d=.5,sig.level=(.05/6), power=.8, type="paired",alternative="greater")
pwr.t.test(n=30,sig.level=(.05/6), power=.8, type="paired",alternative="greater")
library(pwr)
pwr.t.test(d=.4,sig.level=(.05/6), power=.8, type="paired",alternative="greater")
pwr.t.test(d=.4,sig.level=(.05/2), power=.8, type="paired",alternative="greater")
library(irr)
install.package("irr")
install.packages("irr")
library(irr)
?kappa
?irr:kappa
setwd("~/Documents/GitHub/music-copyright-expanded")
#load packages
library(ggplot2)
library(ROCR)
library(verification)
#load data
d<-read.csv("Yuan et al (2022) raw data.csv")
#create percent infringement
d$InfringementAudio<-ifelse(d$Court.Decision.1==1,d$Perceptual.Accuracy...Full.audio,1-d$Perceptual.Accuracy...Full.audio)
d$InfringementMelody<-ifelse(d$Court.Decision.1==1,d$Perceptual.Accuracy...Melody.only,1-d$Perceptual.Accuracy...Melody.only)
d$InfringementLyrics<-ifelse(d$Court.Decision.1==1,d$Perceptual.Accuracy...Lyrics.only,1-d$Perceptual.Accuracy...Lyrics.only)
#omit NAs for lyrics dataset
d.lyric.na<-na.omit(d)
#plot infringement:
#vs PMI:
ggplot(d,aes(x=InfringementAudio,y=PMI,group=Court.Decision))+
geom_point(aes(color=Court.Decision))
ggplot(d,aes(x=InfringementMelody,y=PMI,group=Court.Decision))+
geom_point(aes(color=Court.Decision))
ggplot(d,aes(x=InfringementLyrics,y=PMI,group=Court.Decision))+
geom_point(aes(color=Court.Decision))
#vs Musly:
ggplot(d,aes(x=InfringementAudio,y=Musly,group=Court.Decision))+
geom_point(aes(color=Court.Decision))
ggplot(d,aes(x=InfringementMelody,y=Musly,group=Court.Decision))+
geom_point(aes(color=Court.Decision))
ggplot(d,aes(x=InfringementLyrics,y=Musly,group=Court.Decision))+
geom_point(aes(color=Court.Decision))
#perceptual full audio vs. automated PMI (best human/automated AUCs) - using infringement judgments
ggplot(d,aes(x=InfringementAudio,y=PMI,group=Court.Decision))+
geom_point(aes(color=Court.Decision))+
geom_vline(xintercept = .43)+
geom_hline(yintercept = 46)
#perceptual full audio vs. automated PMI (best human/automated AUCs) - using perceived similarity
ggplot(d,aes(x=AudioSimilarity,y=PMI,group=Court.Decision))+
geom_point(aes(color=Court.Decision))+
geom_vline(xintercept = 2.60,linetype='dotted')+
geom_hline(yintercept = 46,linetype='dotted')
#signal detection analyses:
#PMI
pred <- prediction(d$PMI, d$Court.Decision.1)
#Repeat for:
pred <- prediction(d$Musly, d$Court.Decision.1)
pred <- prediction(d$InfringementAudio, d$Court.Decision.1)
pred <- prediction(d$AudioSimilarity, d$Court.Decision.1)
pred <- prediction(d$InfringementMelody, d$Court.Decision.1)
pred <- prediction(d$MelodySimilarity, d$Court.Decision.1)
pred <- prediction(d.lyric.na$InfringementLyrics, d.lyric.na$Court.Decision.1)
pred <- prediction(d.lyric.na$LyricSimilarity, d.lyric.na$Court.Decision.1)
##
roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
plot(roc.perf)
abline(a = 0, b = 1)
roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
plot(roc.perf)
abline(a = 0, b = 1)
opt.cut = function(perf, pred) {
cut.ind = mapply(FUN = function(x, y, p) {
d = (x-0)^2 + (y-1)^2
ind = which(d == min(d))
c(sensitivity = y[[ind]], specificity = 1-x[[ind]], cutoff = p[[ind]])
}, perf@x.values, perf@y.values, pred@cutoffs)
}
print(opt.cut(roc.perf, pred))
auc.perf = performance(pred, measure = "auc")
auc.perf@y.values
#Significance of ROCs:
roc.area(d$Court.Decision.1,d$PMI) #AUC=0.7247475, p=0.007462554
roc.area(d$Court.Decision.1,d$Musly) #AUC=0.6590909, p=0.0445481
roc.area(d$Court.Decision.1,d$LyricSimilarity) #AUC=0.4392361, p=0.7336617
roc.area(d$Court.Decision.1,d$InfringementLyrics) #AUC=0.4010417, p=0.8429579
roc.area(d$Court.Decision.1,d$MelodySimilarity) #AUC=0.7487374, p=0.003816406
roc.area(d$Court.Decision.1,d$InfringementMelody) #AUC=0.7058081, p=0.01356389
roc.area(d$Court.Decision.1,d$AudioSimilarity) #AUC=0.7777778, p=0.001436054
roc.area(d$Court.Decision.1,d$InfringementAudio) #AUC=0.7070707, p=0.01316813
pred <- prediction(d$PMI, d$Court.Decision.1)
##
roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
plot(roc.perf)
abline(a = 0, b = 1)
roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
plot(roc.perf)
abline(a = 0, b = 1)
opt.cut = function(perf, pred) {
cut.ind = mapply(FUN = function(x, y, p) {
d = (x-0)^2 + (y-1)^2
ind = which(d == min(d))
c(sensitivity = y[[ind]], specificity = 1-x[[ind]], cutoff = p[[ind]])
}, perf@x.values, perf@y.values, pred@cutoffs)
}
print(opt.cut(roc.perf, pred))
auc.perf = performance(pred, measure = "auc")
auc.perf@y.values
roc.area(d$Court.Decision.1,d$PMI) #AUC=0.7247475, p=0.007462554
pred <- prediction(d$Musly, d$Court.Decision.1)
##
roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
plot(roc.perf)
abline(a = 0, b = 1)
roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
plot(roc.perf)
abline(a = 0, b = 1)
opt.cut = function(perf, pred) {
cut.ind = mapply(FUN = function(x, y, p) {
d = (x-0)^2 + (y-1)^2
ind = which(d == min(d))
c(sensitivity = y[[ind]], specificity = 1-x[[ind]], cutoff = p[[ind]])
}, perf@x.values, perf@y.values, pred@cutoffs)
}
print(opt.cut(roc.perf, pred))
auc.perf = performance(pred, measure = "auc")
auc.perf@y.values
pred <- prediction(d$PMI, d$Court.Decision.1)
##
roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
plot(roc.perf)
abline(a = 0, b = 1)
roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
plot(roc.perf)
abline(a = 0, b = 1)
opt.cut = function(perf, pred) {
cut.ind = mapply(FUN = function(x, y, p) {
d = (x-0)^2 + (y-1)^2
ind = which(d == min(d))
c(sensitivity = y[[ind]], specificity = 1-x[[ind]], cutoff = p[[ind]])
}, perf@x.values, perf@y.values, pred@cutoffs)
}
print(opt.cut(roc.perf, pred))
auc.perf = performance(pred, measure = "auc")
auc.perf@y.values
#plot infringement:
#vs PMI:
ggplot(d,aes(x=InfringementAudio,y=PMI,group=Court.Decision))+
geom_point(aes(color=Court.Decision))
ggplot(d,aes(x=InfringementMelody,y=PMI,group=Court.Decision))+
geom_point(aes(color=Court.Decision))
ggplot(d,aes(x=InfringementLyrics,y=PMI,group=Court.Decision))+
geom_point(aes(color=Court.Decision))
#vs Musly:
ggplot(d,aes(x=InfringementAudio,y=Musly,group=Court.Decision))+
geom_point(aes(color=Court.Decision))
ggplot(d,aes(x=InfringementMelody,y=Musly,group=Court.Decision))+
geom_point(aes(color=Court.Decision))
ggplot(d,aes(x=InfringementLyrics,y=Musly,group=Court.Decision))+
geom_point(aes(color=Court.Decision))
#perceptual full audio vs. automated PMI (best human/automated AUCs) - using infringement judgments
ggplot(d,aes(x=InfringementAudio,y=PMI,group=Court.Decision))+
geom_point(aes(color=Court.Decision))+
geom_vline(xintercept = .43)+
geom_hline(yintercept = 46)
#perceptual full audio vs. automated PMI (best human/automated AUCs) - using perceived similarity
ggplot(d,aes(x=AudioSimilarity,y=PMI,group=Court.Decision))+
geom_point(aes(color=Court.Decision))+
geom_vline(xintercept = 2.60,linetype='dotted')+
geom_hline(yintercept = 46,linetype='dotted')
#plot infringement:
#vs PMI:
ggplot(d,aes(x=InfringementAudio,y=PMI,group=Court.Decision))+
geom_point(aes(color=Court.Decision))
ggplot(d,aes(x=InfringementMelody,y=PMI,group=Court.Decision))+
geom_point(aes(color=Court.Decision))
ggplot(d,aes(x=InfringementLyrics,y=PMI,group=Court.Decision))+
geom_point(aes(color=Court.Decision))
#vs Musly:
ggplot(d,aes(x=InfringementAudio,y=Musly,group=Court.Decision))+
geom_point(aes(color=Court.Decision))
ggplot(d,aes(x=InfringementMelody,y=Musly,group=Court.Decision))+
geom_point(aes(color=Court.Decision))
ggplot(d,aes(x=InfringementLyrics,y=Musly,group=Court.Decision))+
geom_point(aes(color=Court.Decision))
#perceptual full audio vs. automated PMI (best human/automated AUCs) - using infringement judgments
ggplot(d,aes(x=InfringementAudio,y=PMI,group=Court.Decision))+
geom_point(aes(color=Court.Decision))+
geom_vline(xintercept = .43)+
geom_hline(yintercept = 46)
#perceptual full audio vs. automated PMI (best human/automated AUCs) - using perceived similarity
ggplot(d,aes(x=AudioSimilarity,y=PMI,group=Court.Decision))+
geom_point(aes(color=Court.Decision))+
geom_vline(xintercept = 2.60,linetype='dotted')+
geom_hline(yintercept = 44.6,linetype='dotted')
#plot infringement:
#vs PMI:
ggplot(d,aes(x=InfringementAudio,y=PMI,group=Court.Decision))+
geom_point(aes(color=Court.Decision))
ggplot(d,aes(x=InfringementMelody,y=PMI,group=Court.Decision))+
geom_point(aes(color=Court.Decision))
ggplot(d,aes(x=InfringementLyrics,y=PMI,group=Court.Decision))+
geom_point(aes(color=Court.Decision))
#vs Musly:
ggplot(d,aes(x=InfringementAudio,y=Musly,group=Court.Decision))+
geom_point(aes(color=Court.Decision))
ggplot(d,aes(x=InfringementMelody,y=Musly,group=Court.Decision))+
geom_point(aes(color=Court.Decision))
ggplot(d,aes(x=InfringementLyrics,y=Musly,group=Court.Decision))+
geom_point(aes(color=Court.Decision))
#perceptual full audio vs. automated PMI (best human/automated AUCs) - using infringement judgments
ggplot(d,aes(x=InfringementAudio,y=PMI,group=Court.Decision))+
geom_point(aes(color=Court.Decision))+
geom_vline(xintercept = .43)+
geom_hline(yintercept = 46)
#perceptual full audio vs. automated PMI (best human/automated AUCs) - using perceived similarity
ggplot(d,aes(x=AudioSimilarity,y=PMI,group=Court.Decision))+
geom_point(aes(color=Court.Decision))+
geom_vline(xintercept = 2.60,linetype='dotted')+
geom_hline(yintercept = 44,linetype='dotted')
pred <- prediction(d$Musly, d$Court.Decision.1)
##
roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
plot(roc.perf)
abline(a = 0, b = 1)
roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
plot(roc.perf)
abline(a = 0, b = 1)
opt.cut = function(perf, pred) {
cut.ind = mapply(FUN = function(x, y, p) {
d = (x-0)^2 + (y-1)^2
ind = which(d == min(d))
c(sensitivity = y[[ind]], specificity = 1-x[[ind]], cutoff = p[[ind]])
}, perf@x.values, perf@y.values, pred@cutoffs)
}
print(opt.cut(roc.perf, pred))
auc.perf = performance(pred, measure = "auc")
auc.perf@y.values
#Logistic regression:
#Full model (Excluding unhelpful lyric data with missing data)
glm.fit <- glm(Court.Decision.1~AudioSimilarity+MelodySimilarity+InfringementAudio+InfringementMelody+PMI+Musly,data=d,family = binomial)
summary(glm.fit)
#Logistic regression:
#Full model (Excluding unhelpful lyric data with missing data)
glm.fit <- glm(Court.Decision.1~AudioSimilarity+MelodySimilarity+PMI+Musly,data=d,family = binomial)
summary(glm.fit)
